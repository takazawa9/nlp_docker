{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudachi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "\n",
    "tokenizer_obj = dictionary.Dictionary().create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['国家', '公務', '員']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = tokenizer.Tokenizer.SplitMode.A\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"国家公務員\", mode)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['国家', '公務員']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = tokenizer.Tokenizer.SplitMode.B\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"国家公務員\", mode)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['国家公務員']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = tokenizer.Tokenizer.SplitMode.C\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"国家公務員\", mode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あいみょん\t名詞,固有名詞,人名,一般,*,*,あいみょん,アイミョン,アイミョン\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "きゃりーぱみゅぱみゅ\t名詞,固有名詞,人名,一般,*,*,きゃりーぱみゅぱみゅ,キャリーパミュパミュ,キャリーパミュパミュ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "\n",
      "あいみょん\n",
      "きゃりーぱみゅぱみゅ\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "# Neologdの読み込み\n",
    "tagger = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "input = 'あいみょんときゃりーぱみゅぱみゅ。'\n",
    "\n",
    "result = tagger.parse(input)\n",
    "print(result)\n",
    "\n",
    "node = tagger.parseToNode(input)\n",
    "target_parts_of_speech = ('名詞', )\n",
    "while node:\n",
    "    if node.feature.split(',')[0] in target_parts_of_speech:\n",
    "        print(node.surface)\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT(日本語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['どんなに', '勉強', 'して', 'も', '全然', '頭', 'が', '良く', 'なら', 'ない']\n"
     ]
    }
   ],
   "source": [
    "# 参考:https://yukoishizaki.hatenablog.com/entry/2019/11/27/151018\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertForMaskedLM, BertConfig, BertTokenizer\n",
    "from pyknp import Juman\n",
    "\n",
    "BASE_PATH = '/home/jovyan/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers'\n",
    "BERT_CONFIG = 'config.json'\n",
    "BERT_MODEL = 'pytorch_model.bin'\n",
    "VOCAVULARY_LIST = 'vocab.txt'\n",
    "\n",
    "jumanpp = Juman()\n",
    "\n",
    "# 形態素解析\n",
    "text = 'どんなに勉強しても全然頭が良くならない'\n",
    "result = jumanpp.analysis(text)\n",
    "tokenized_text =[mrph.midasi for mrph in result.mrph_list()]\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'どんなに', '勉強', 'して', 'も', '全然', '[MASK]', 'が', '良く', 'なら', 'ない', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Mask \n",
    "tokenized_text.insert(0, '[CLS]')\n",
    "tokenized_text.append('[SEP]')\n",
    "\n",
    "masked_index = 6 # Maskしたいtextのindex \n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/jovyan/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    1, 6547,   19,   23,    1,    4,   11, 4161,  371,   46,    3]])\n"
     ]
    }
   ],
   "source": [
    "# Bert model\n",
    "config = BertConfig.from_json_file(os.path.join(BASE_PATH, BERT_CONFIG))\n",
    "model = BertForMaskedLM.from_pretrained(os.path.join(BASE_PATH, BERT_MODEL), config=config)\n",
    "tokenizer = BertTokenizer(os.path.join(BASE_PATH, VOCAVULARY_LIST), do_lower_case=False, do_basic_tokenize=False)\n",
    "\n",
    "# token化\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "print(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['成績', '頭', '気持ち', '方', '態度']\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "model.eval()\n",
    "\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "_, predicted_indexes = torch.topk(predictions[0, masked_index], k=5)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indexes.tolist())\n",
    "print(predicted_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
